## Материалы модуля 10

<div align="center">
  <img src="../images/dls.png">
</div>

### Low-resource языки и non-English языки.

Подавляющее большинство исследований и моделей сфокусировано на английском языке. В этом блоке мы обсудим уникальные вызовы, связанные с разработкой решений для малоресурсных и нетипичных для мира ML языков (включая русский). Мы рассмотрим практические методики: transfer learning и fine-tuning с английских моделей, активное обучение с привлечением данных, а также подходы с использованием самообучения (self-supervised learning) для извлечения универсальных речевых представлений, не зависящих от языка.

### Лекция
В лекции мы рассмотрим подходы построения систем распознавания речи для Low-resource доменов. В качестве якоря, будем использовать задачу  распознавания речи на киргизском и русском языках. Лекция условно будет разделена на два раздела: (1) Модели и подходы обучения; (2) Данные. 
В первой части обсудим перенос знаний с моделей для родственных языков, а также концепцию обучения на не размеченных данных в контексте этой задачи. Постараемся выделить плюсы и минусы каждого из подходов, оценить целесообразность проведения тех или иных экспериментов.
В части посвященной данным будут предложены подходы создания обогащения обучающей выборки: open source, CTC-Forced alignment, синетика, pseudolabels, in house разметка. Определим чем каждый из подходов незаменим, и что привносит в модель. Оценим влияние каждого из подходов.


### Семинар

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepLearningSchool/Speech/blob/main/week_11_speech_low_resource_languages/Practice/dls.ipynb)

На семинаре попробуем решить задачу переноса знаний на родственный (киргизский) язык. Рассмотрим как можно дообучить whisper распознавать язык, который он ранее не видел. Обсудим пайплайн обучения от загрузки данных, до инференса.



### Домашнее задание
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepLearningSchool/Speech/blob/main/week_11_speech_low_resource_languages/Homework/dz.ipynb)

Домашнее задание будет разделено на две части, в которых необходимо модифицировать код, рассмотренный на семинаре, реализовав два, незаменимых на практике механизма:
(1) Взвешивание наборов данных в рамках одного датасета (семплирование примеров с разной частотностью);
(2) Аккумуляцию градиента, снижающего дисперсию градиента для более стабильного обучения.
